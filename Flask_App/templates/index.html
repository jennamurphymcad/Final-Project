<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Final Project - Group 8</title>
  <link rel ="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">

  <!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"> -->
  <link rel="stylesheet" href="../static/css/style.css">
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@500&family=Roboto:wght@100;300;400&display=swap" rel="stylesheet">
</head>

<body>
    <!-- <nav class="navbar navbar-expand-md navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-md navbar-light">
        <div class="container-fluid">
          <a class="navbar-brand" href="#">Twitter Analysis</a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse justify-content-end" id="navbarNavDropdown">
            <ul class="navbar-nav">

              <!-- <li class="nav-item">
                <a class="nav-link active" aria-current="page" href="#">Home</a>
              </li> -->
              <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button" data-bs-toggle="dropdown" aria-expanded="false">
                  Process
                </a>
                <ul class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                  <li><a class="dropdown-item" href="#">Max-Temp</a></li>
                  <li><a class="dropdown-item" href="#">Humidity</a></li>
                  <li><a class="dropdown-item" href="#">Cloudiness</a></li>
                  <li><a class="dropdown-item" href="#">Wind Speed</a></li>
                </ul>
              </li>
              <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button" data-bs-toggle="dropdown" aria-expanded="false">
                  Test ML Model
                </a>
                <ul class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                  <li><a class="dropdown-item" href="/test">Test a Tweet</a></li>
                  <li><a class="dropdown-item" href="/test_csv_data">Test Submission Data Set</a></li>
                </ul>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="/data">Train Data</a>
              </li>

            </ul>
          </div>
        </div>
      </nav>

  <!-- main summary -->
  <main>
    <div class="container-fluid my-container vis-main-summary">
      <div class="row">
        <div class="col-lg-12 col-md-12">
          <h1>Project Summary</h1>
          <hr>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-12 col-md-12">
          <!-- <img src="#" alt="Main Fig Example"> -->
          <p>
            Twitter has become an important communication channel in times of emergency. Since nearly everyone has a smartphone, people can "announce" an emergency they’re observing in real-time. Because of this, more agencies are interested in programmatically monitoring Twitter (i.e. disaster relief organizations and news agencies). But, it’s not always clear whether a person’s words are actually announcing a disaster. 
            <!-- <hr>
            INSERT IMAGE
            <hr> -->
            This project attempts to predict which tweets are about real disasters and which are not. 
            The dataset is from a Kaggle Machine Learning competition.
          </p>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-12 col-md-12">
          <!-- <img src="#" alt="Main Fig Example"> -->
          <h2>Dataset</h2>
          <p>The overall dataset (corpora) contains 10,000 tweets (documents) of which 7,613 are the training dataset and have been classified (by a human) as "emergency" or "not an emergency". 
            This is known as "supervised model". A further 3,700 are part of a testing dataset for which the classification is unknown to us. 
            Of the training set 4342 tweets are classified as 0 or "not an emergency" and 3271 are classified as 1 or "emergency" - the dataset is not perfectly balanced.

            <ul>Tweet text examples:
            <br>
            
            <li>"13,000 people receive #wildfires evacuation orders in California"</li>
            <li>"Forest fire near La Ronge Sask. Canada"</li>
            <Li>"I'm on top of the hill and I can see a fire in the woods..."</Li>
            <li>"I'm afraid that the tornado is coming to our area..."</li>

            <li>"Crying out for more! Set me ablaze"</li>
            <li>"What a wonderful day!"</li>
            <li>"#Flood in Bago Myanmar #We arrived Bago"</li>

          </p>
          </ul>
          <img src="../static/assets/images/wordcloud.png" alt="wordcloud">


          
          <h2>Methodology</h2>
          <p>
            Making predictions such as "real" or "not real" or "good" or "not good" from raw text is known as a classification problem. 
            Taking text and analyzing in a way that a machine learning model can make prediction is call Natural Language Processing (NLP). 
            This project uses the python library scikit-learn to analyze the text and make predictions.
            <hr>
            <h4>Tokenization</h4>
            <hr>
            Tokenization converts the dataset to a list of individual unique tokens (known as the vocabulary- most of which will be words.
            With no filtering this dataset has 21,637 tokens.
            <hr>
            <h4>Vectorization</h4>
            <hr>
            Each document (tweet) is then transformed into a vector with 1 row and 21,637 columns where each column represents a word from the vocabulary.  
            0s and 1s represent the absence or presence of that particular word.  
            The corpora consist of a 7613x21637 sparse matrix with 111,497 stored elements in Compressed Sparse Row format.
            <hr>
            <h4>Baselining</h4>
            <hr>
            The problem is now a numeric one and initial logistic regression model can be built. 
            The mean cross-validation accuracy is 0.711.  
            After tuning the result by adjusting the regularization parameter C, the cross-validation accuracy is improved to 0.730.
          </p>
          <h2>Improving the Model</h2>
            CountVectorizer extracts tokens using a regular expression "\b\w\w+\b" which finds all sequences of characters that consist of at least 2 letters or numbers (\w) and are separated by word boundaries. 
            It splits contractions like doesn't into doesn and t.  
            It converts all words to lowercase. 
            Lemmatization is the process of contracting similar words and plurals down to the verb root or lemma.  
            Lemmatization reduces the token count from 21,637 to 14,703. 
            Increasing the minimum word frequency can remove low-frequency words which are often garbage or misspelled words e.g. '0ubg9wfyge', '0uk0h9hozn', '0usdi5jcho' .  
            An optimization for min_df was run using values in the range 1 to 50. 
            The best cross-validation accuracy was 0.73 at a min_df of 4. 
            Although not an improvement the number of features is reduced from 14,703 to 2,795
            <hr>
            <h4>Rescaling data with tf-idf and n-Grams</h4>
            <hr>
            Term Frequency (TF) - Inverse Document Frequency (IDF) - give a high weight to any term that appears often in a particular document, but not in very many documents in the corpus. 
            If a word appears many times in a document, but not in very many documents, it is likely to be descriptive of those documents.
            The approach up until now has been to discard the word order and only consider a so-called “bag of words”.  
            Meaning in text also comes from the order of the words and to attempt to simulate this n-Grams which link consecutive words to create new features are created.
            The heatmap shows cross-validation scores versus 1-1, 1-2, and 1-3 n-Grams versus the hyper-parameter C. 
            <br>
            <h2>Conclusions</h2>
            The model was difficult to improve beyond the initial cross-validation score of 0.73 – even using lemmatization, the td-idf methodology and n-Grams. 
            The number of features were reduced considerably – almost by a factor of 10 and could have gone much lower with only a minor reduction accuracy. 
            On larger datasets this would improve the processing time.
            <br>
            <br>
            Perhaps the amount of information contained in a tweet is too small and the critical information is contained in single word.  
            The above visualization shows the most significant tokens with their model coefficients.



            <div class="row">
                <div class="col-lg-12 col-md-12">
            <img src="../static/assets/images/coefficients.png" alt="Coefficients">
                  </div>
            </div>
            <img src="../static/assets/images/heatmap.png" alt="heatmap">
          <!-- </div>   -->
        </div>
      </div>
    </div>
    
    <!-- side navigation -->
    <div class="container-fluid my-container vis-side-navigation">
      <div class="row">
        <!-- <div class="col-lg-12 col-md-12 col-sm-12">
          <h2>Visualizations</h2>
          <hr>
        </div> -->
      </div>

      <div class="row">
        <div class="col-lg-12 col-md-12 col-sm-3 col-3">
          <a href="#"><img src="../static/assets/tweet_screenshot.png" alt="Fig 1"></a>
        </div>
        <div class="col-lg-6 col-md-6 col-sm-3 col-3">
          <a href="#"><img src="../assets/images/Fig2.png" alt="Fig 2"></a>
        </div>
        <div class="col-lg-6 col-md-6 col-sm-3 col-3">
          <a href="#"><img src="../assets/images/Fig3.png" alt="Fig 3"></a>
        </div>  

      </div>
    </div>
  </main>



  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-gtEjrD/SeCtmISkJkNUaaKMoLD0//ElJ19smozuHV6z3Iehds+3Ulb9Bn9Plx0x4" crossorigin="anonymous"></script>

  <!-- <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script> -->
  <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script> -->
  <!-- <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script> -->
</body>

</html>
